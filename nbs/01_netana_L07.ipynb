{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968d468803c60b96",
   "metadata": {},
   "outputs": [],
   "source": "#| default_exp netana_L07"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44d5fad4f64b642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_tool import Graph\n",
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d964d96884230a3d",
   "metadata": {},
   "source": [
    "# Lecture 07\n",
    "> Communities, Clusters, Motifs\n",
    "\n",
    "---\n",
    "* Community finding\n",
    "* Modularity\n",
    "* Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66efc0bbccc3098c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from graph_tool import Graph\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e3e47c9e015642",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# L is Laplacian Matrix\n",
    "# D is Diagonal Degree Matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a3df6505743266",
   "metadata": {},
   "source": [
    "\n",
    "So basically in the last lecture we talked about network partitioning which separated a network into $K$ equal size parts while minimizing the cut size.\n",
    "\n",
    "The question that is now obvious is what happens if we don't want balanced partitions because it wouldn't represent the structure in our network well.\n",
    "\n",
    "Partitioning forces a structure upon our network that might or might not be there essentially. But we would rather want to find out what the internal grouping structure of a network, without making assumptions about it beforehand.\n",
    "\n",
    "This is where **community detection** comes in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7de33bf6ce980f",
   "metadata": {},
   "source": [
    "\n",
    "## Community\n",
    "> This section tells us how to qualify what a community is, how it differs from other groupings like partitions or node roles, introduces different types of detection methods, discusses community detection as a hard problem, and gives an example of how challenging and relevant this is at scale.\n",
    "\n",
    "A community is a group of nodes that is formed by mutual adjacency, proximity, or reachability. It suggests the presence of real-world interaction for a common purpose.\n",
    "\n",
    "Nodes in a community are more likely to connect to each other than to nodes from other communities.\n",
    "\n",
    "We can capture this by: Given connected subgraph $C$, let again the internal degree $d_i^{int}$ of node $i$ be the number of links to other nodes in $C$, external degree $k_i^{ext}$ number of links to the rest.\n",
    "\n",
    "Then $C$ is a strong community if each node in $C$ has $k_i^{int}(C) > k_i^{ext}(C)$\n",
    "\n",
    "$C$ is a weak community if $\\sum_{i\\in C} k_i^{int}(C) > \\sum_{i\\in C}k_i^{ext}(C)$\n",
    "\n",
    "E.g. each clique is a strong community\n",
    "\n",
    "Note the difference to\n",
    "\n",
    "* Partition - we do not assume predefined numbers or sizes of groups, or non-overlap\n",
    "* Nodes with similar roles - specific characteristics or function of single nodes in a network (e.g. peripheral, center of a star, member of a clique). These nodes belong to a category but don't necessarily form a community.\n",
    "\n",
    "An equivalence relation of the vertices corresponds to a partitioning (into equivalent classes) and a role assignment, not communities.\n",
    "\n",
    "Example: Network from data of belgian mobile phone company. 2.6 million users, calls over 6 months. Blondel et al.'s analysis reveals 261 communities of >100 customers (node size proportional to #customers, color language spoken, red French, green Dutch\n",
    "\n",
    "\n",
    "\n",
    "Our goal here will be to find algorithms that can detect the presence and the size and type of each of these communities in our network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97dbeda082b9c37",
   "metadata": {},
   "source": [
    "\n",
    "## Community Detection\n",
    "> How to Identify Communities?\n",
    "\n",
    "More on this topic in Chapter 14 Newman\n",
    "\n",
    "Beyond the term Community there is also a mayor problem of detecting communities in networks. This is not easy and not every network does necessarily have a community. So algorithms have to be able to detect them if they are there but also be able to say that the arent. It seems like there are two mayor methods. They are handeled in two subsections, namely Modularity and Divisive, which seem to be just two different methods for doing this.\n",
    "\n",
    "\n",
    "* Community detection: Major research topic\n",
    "* Many definitions of criteria and many methods exist.\n",
    "\n",
    "Two main aspects: An objective and a method to optimise it.\n",
    "\n",
    "Paradigms to build communities:\n",
    "\n",
    "* Agglomerative: start from single entities, increase\n",
    "* Divisive: Start with full graph, remove edges, e.g. based on the importance of edges.\n",
    "\n",
    "Sometimes we have additional constraints, e.g. the number of groups.\n",
    "\n",
    "Many goals constitute hard optimization problems, and thus many heuristics and approximation methods exist.\n",
    "\n",
    "Note: There simply might not be good communities in a graph (Question: How do we know?).\n",
    "\n",
    "What about the number of possible solutions here?\n",
    "\n",
    "Given by Bell number, recursively $B_{N+1} = \\sum_{k=0}^N B_k, B_0 = 1$\n",
    "\n",
    "Dobinski formula $B_{N+1} = \\frac{1}{e}\\sum_{k=0}^\\inf \\frac{k^N}{k!}$\n",
    "\n",
    "1, 1, 2, 5, 15, 52, 203, 877, 4140, 21147, 115975, 678570, 4213597, 27644437,...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3935916b990d764a",
   "metadata": {},
   "source": [
    "### Community Detection Measures — Modularity\n",
    "\n",
    "Modularity: An objective for community detection. Measures the extent to which like is connected to like (within a community) for a given partitioning in communities.\n",
    "\n",
    "Strictly less than one, positive if there are more \"like-to-like\" edges than expected by random chance (configuration model). Negative values $(\\geq-0.5)$ indicate disassortative mixing.\n",
    "$$Q = \\frac{1}{\\underbrace{2M}_{\\text{Normalise}}}\\sum_{ij}\\left(\\underbrace{A_{ij}}_{\\text{Actual eges}}-\\frac{k_ik_j}{\\underbrace{2M}_{\\text{Expected edges}}}\\right)\\underbrace{\\delta_{g_ig_j}}_{\\text{Given partitioning\\ in communities }g_k}$$\n",
    "\n",
    "Note that $\\sum_{\\text{edges}(i,j)}\\delta_{g_ig_j} = \\frac{1}{2}\\sum g_{ij}A_{ij} \\delta_{g_ig_j}$ is the number of edges between nodes in the same community.\n",
    "\n",
    "Expected connection in a random null model with degree distribution $\\frac{k_i k_j}{2M}$ as we have $k_i$ opportunities to end an edge from i that one of the stubs at j, which have a fraction of $\\frac{k_j}{2M}$ of all stubs.\n",
    "\n",
    "Sometimes the equivalent community-only formula is used $$Q = \\frac{1}{2M}\\sum_c \\left( E_c - \\gamma \\frac{K_c^2}{2M}\\right)$$\n",
    "\n",
    "with $E_c$ edges in community $c, K_c$ sum of degrees of nodes in $c$, and $\\gamma$ an additional resolution parameter.\n",
    "Communities should have at least density $\\gamma$ while between them, it should be lower. Higher $\\gamma$ leads to more communities. See e.g. networkx implementation.\n",
    "\n",
    "(Note that we can use this formula for easier optimisation / computation - merge edge lists.)\n",
    "\n",
    "* Maximum modularity seems to work well for communities.\n",
    "* It can be used to evaluate quality of results from community detection algorithms or as objective for an algorithm.\n",
    "* Examples for Optimal Partition with high $M$, suboptimal partition with low $M$, single community with $M=0$, negative modularity with negative $M$.\n",
    "* Maximum modularity is not always intuitive, examples with non-local behaviour, a clique $K_3$ with leaves, scaling behaviour, clusters represented as colours.\n",
    "* Note: Similarity to assortativity, also finds communities in null model networks (model ignores search for communities in statistical manner - overfitting, finds high modularity communities, p-hacking)\n",
    "* Resolution limit max. $\\sqrt{2E}$ communities: Prefers communities above a certain size (underfitting).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2264bbc6e60c5d2e",
   "metadata": {},
   "source": [
    "### Modularity Methods\n",
    "\n",
    "#### Community Detection — Agglomerative\n",
    "\n",
    "Maximum modularity problem is unfortunately NP-complete.\n",
    "Simple heuristic: Greedy joining\n",
    "\n",
    "Iteratively joins nodes if the move increases the new partition's modularity ($N-1$ merges, $\\mathcal{O}(N^2 log N)$ — similar to our KL partitioning, up to engineering).\n",
    "\n",
    "* Step 1: Assign each node a community of its own. Hence we start with $N$ communities.\n",
    "* Step 2: Inspect each pair of communities connected by at least one link and compute the modularity variation obtained if we merge these two communities.\n",
    "* Step 3: Identify the community paris for which $\\Delta M$ is the largest and merge them. Note that modularity of a particular partition is always calculated from the full topology of the network.\n",
    "* Step 4: Repeat step 2 until all nodes are merged into a single community.\n",
    "* Step 5: Record for each step and select the partition for which the modularity is maximal.\n",
    "\n",
    "Unbounded approximation ratio.\n",
    "\n",
    "Compromise of very fast and reasonable quality: Louvrain method (Bondel et al.) Agglomerative multilevel method.\n",
    "\n",
    "Consider individual node moves to different communities until no improvement is possible (Consider neighbours community). After initial merging, create new network with communities as nodes and repeat. Depending on structure reported to be somewhere between $\\mathcal{O}(N \\log N)$ and $\\mathcal{O}(N^2)$ in practice.\n",
    "\n",
    "Problem: Communities don't need to be connected $\\rightarrow$ Improvement Leiden algorithm: Refinement Step\n",
    "\n",
    "**Modularity Take-away**\n",
    "\n",
    "* Concept and formula\n",
    "* Heuristics\n",
    "\n",
    "Proceed with caution - it looks simple and interpretable with reasonable null model comparison, but results might be far from the expected.\n",
    "However, you will find a lot of methods in many tools, thus our discussion of it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3dd16464d30b7d",
   "metadata": {},
   "source": [
    "\n",
    "#### Community Detection — Divisive\n",
    "\n",
    "Create communities by iteratively removing edges that connect nodes with low similarity.\n",
    "\n",
    "Creates a hierarchy.\n",
    "\n",
    "E.g. Girvan-Newman:\n",
    "\n",
    "* Step 1: Define a centrality measure for links\n",
    "    * Link betweenness is the number of shortest paths between all node paris that run along a link (relative to all). $\\mathcal{O}(MN)$ or for sparse  $\\mathcal{O}(N^2)$\n",
    "    * Random-walk betweenness. A pair of nodes $m$ and $n$ are chosen at random. A walker starts at $m$, following each adjacent link with equal probability unitl it reaches $n$. Random walk betweenness $x_{ij}$ is the probability that the link $i \\rightarrow j$ was crossed by the walker after averaging over all possible choices for starting nodes $m$ and $n$ $\\mathcal{O}(MN^2)$\n",
    "* Step 2: Hierarchical Clustering\n",
    "    * Compute the centrality of each link\n",
    "    * Remove the link with the largest centrality; in case of a tie, choose one randomly (!bad).\n",
    "    * Recalculate the centrality of each link for the altered network.\n",
    "    * Repeat until all links are removed (yields a dendogram).\n",
    "\n",
    "\n",
    "Computational complexity:\n",
    "\n",
    "* Step 1a (calculation betweenness centrality): $\\mathcal{O}(N^2)$ for sparse networks\n",
    "* Step 1b (Recalculation of betweenness $\\mathcal{O}(N^3)$ centrality for all links: $\\mathcal{O}(LN^2)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4400c703d4f7d8",
   "metadata": {},
   "source": [
    "\n",
    "#### How does the Divisive Method for community detection work?\n",
    "\n",
    "* What is the process of finding communities in network data?\n",
    "\n",
    "* What is modularity? How is it defined?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff0f4b228c82ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    " # What kind of code can we write about community detection? We can probably load any graph and check if there is a community present in it and then get the characteristic metrics for these communities that we can then report on.\n",
    "\n",
    "def find_community(graph: Graph):\n",
    "    return {}\n",
    "\n",
    "def report_communities(communities):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5914dac156dcd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "G = Graph()\n",
    "\n",
    "community = find_community(G) # so something like this could be interesting.\n",
    "report_communities(community) # And then using this community data structure we could maybe report on it.\n",
    "# Now i definately don't know if this works this way, at least a good guess is that something exists here that we can report on and that we can acutally do in code and probably also usign functions that are already implemented either in graph_tool or networkx.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f002383a1a33fadd",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "* Clustering groups data points from a data set into subsets (clusters) that are homogeneous (compared to the rest - adding points might change grouping!)\n",
    "* In data science/machine learning is often considered unsupervised learning\n",
    "* Require some notion of similarity\n",
    "* Usually similarity matrix $S$ (or dissimilarity/distance)\n",
    "1) Define some distance / similarity\n",
    "2) Apply an optimisation that optimises an objective function, e.g. \"close\" points in clusters (e.g. k-means)\n",
    "\n",
    "* Graph clustering partitions the nodes (usually) of a graph into clusters, i.e. node sets. Clusters might be disjoint, overlapping, or nested.\n",
    "* Often: goal of having many intra-cluster edges and few inter-cluster edges. The most popular approach for graph clustering is extraction of tightly connected subgroups of nodes (which we termed community detection)\n",
    "* Many graph clustering techniques using this approach are based on agglomerative clustering algorithms.\n",
    "* Often clustering in general form is less focused on structure, rather attributes (cluster might be disconnected in the network model — but you might argue there is another network on the attributes) and without the assumption that clusters are (more) densely connected and sparse connectivity in between.\n",
    "* In practice also clustering of multivariate data / attributed graphs where topological structure is only a part.\n",
    "* Examples: Clustering based on density of connections vs. clustering based on commonality of neighbors\n",
    "\n",
    "Relation Clustering vs. Community Detection\n",
    "\n",
    "* Several sources: Clustering $\\approx$ Community detection\n",
    "* Several sources: Clustering $\\neq$ Community detection\n",
    "* Several sources: Clustering $\\subset$ Community detection (e.g. Newman)\n",
    "* Several sources: Clustering $\\supset$ Community detection (e.g. Bader et al.)\n",
    "\n",
    "Surely strong overlap and roots/focus in, ah, different communities.\n",
    "E.g. Edge betweenness clustering - Girvan-Newman\n",
    "Note: We already encountered a reference to clustering, the clustering coeficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d988d5e9414721e8",
   "metadata": {},
   "source": [
    "\n",
    "### Hierarchical Clustering\n",
    "\n",
    "Hierarchical clustering does not create simply a partitioning, but a multilevel tree structure of partitions, where each cluster except for the root is a subcluster of a supercluster.\n",
    "\n",
    "* Root cluster (contains all points)\n",
    "* Levels cut through the hierarchy and constitute clusterings (not necessarily horizontal)\n",
    "* At the bottom data elements / nodes\n",
    "\n",
    "From bottom to top the cluster distance can be graphed in a dendogram.\n",
    "\n",
    "**Clustered graph**\n",
    "$$C = \\left(\\underbrace{G}_{\\text{Graph}}, \\underbrace{T}_{\\text{Inclusion Hierarchy}}\\right)$$\n",
    "\n",
    "Clustered drawing: Disjoint regions for disjoint clusters, representing the hierarchy.\n",
    "Note: In such an inclusion hierarchy, we lose the information on the cluster distance.\n",
    "\n",
    "* Again, we could proceed in agglomerative or divisive fashion.\n",
    "* The similarities can be given as input or computed based on input data / structure\n",
    "* Many methods / classes of methods existing\n",
    "\n",
    "Similarity:\n",
    "\n",
    "1) Structural equivalence — share neighbours\n",
    "2) Regular equivalence — have neighbors that are similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308c369f169db07a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Structural Similarity\n",
    "Measures:\n",
    "\n",
    "* Common neighbors $n_ij = \\sum_k A_{ik} A_{kj}$ - this disregards the nodes' degrees\n",
    "* Jaccard coefficient - normalize $n_{ij}$ betwen 0 and 1 by dividing by total number of distinct neighbors $J_{ij} = \\frac{n_{ij}}{k_i+k_j-n_ij}$ (count common neighbors once)\n",
    "* Cosine — defined on vectors:\\\n",
    "    Dot product $x \\cdot y = |x||y|\\cos\\theta \\rightarrow \\cos \\theta = \\frac{x\\cdot y}{|x||y|}$\\\n",
    "    $0$ if orthogonal / independent\\\n",
    "    Here: Regard rows of adjacency matrix $A$ as vectors and use cosine as similarity Dot product for undirected graphs simply $n_{ij}$ for $i$ and $j$. Thus similarity $$\\sigma_{ij} = \\cos \\theta = \\frac{\\sum_k A_{ik} A_{kj}}{\\sqrt{\\sum_k A_{ik}^2}\\cdot \\sqrt{\\sum_k A_{jk}^2}}$$\n",
    "    Note that for simple unweighted graphs $A_{ik}^l = A_{ik}$ (only 0 or 1), $\\sum A_{ik} = k_i$ (degree of i). Thus $$\\sigma_{ij} = \\frac{n_{ij}}{\\sqrt{k_i k_j}}$$\n",
    "\n",
    "    * Then similarity of i and j is number of common neighbours divided by geometric mean of degrees. (0 by convention for degree zero).\n",
    "    * Value of 0 for no sharing, 1 for the exact same neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba35839a46875ce3",
   "metadata": {},
   "source": [
    "\n",
    "#### SAHN\n",
    "Sequential agglomerative hierarchical non-overlapping (SAHN) clustering techniques belong to the classical clustering methods applied heavily in many application domains.\n",
    "\n",
    "1) Assign each node to its own cluster (N cluster)\n",
    "2) Iteratively: In each step, decrease number of clusters by one by merging two \"most similar\" clusters.\n",
    "\n",
    "Finish either at the desired number of clusters or when only one cluster left.\n",
    "\n",
    "* Find similar nodes:  (Dis)Similarity / Distance matrix\n",
    "* $S_{ij}$ contains distance value from node $i$ to node $j$\n",
    "* Merge similar clusters: Need inter-cluster distance = linkage\n",
    "\n",
    "Typical linkage strategies (similarity between groups)\n",
    "\n",
    "* Single linkage - use smallest distance / dissimilarity (\"merge by nearest neighbours\"). Might create stretches.\n",
    "* Complete linkage - use largest distance / dissimilarity (\"merge by farthest neighbours\").\n",
    "* Average linkage - use average of all pairs of nodes (weighted average after merging)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4b234bd72e052b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Ravasz algorithm**\n",
    "1) Similarity: connect nodes that share many neighbours\\\n",
    "    Topology overlap matrix $$\\sigma_{ij} = \\frac{J(i,j)}{min(k_i, k_j) + 1 - \\Theta(A_{ij})}$$\n",
    "$J(i, j)$ simply is $n_{ij}$ plus 1 in case of a direct link (i, j are not common neighbors)\n",
    "   $$\\Theta(A_{ij}) =\n",
    "   \\begin{cases}\n",
    "        0: A_{ij} \\leq 0 \\\\\n",
    "        1: \\text{else}\\\\\n",
    "    \\end{cases}$$\n",
    "   $$\\sigma_{ij}=\n",
    "   \\begin{cases}\n",
    "        0: \\text{no direct link or common neighbors}\\\\\n",
    "        1: \\text{direct link and same neighbors}\\\\\n",
    "    \\end{cases}$$\n",
    "2) Merging: what are similarities between groups?\n",
    "    Average Linkage\n",
    "3) Building the hierarchy:\n",
    "    1) Each node is a singleton community\n",
    "    2) Find the pair with the highest similarity and merge\n",
    "    3) Calculate similarities for a new community\n",
    "    4) Repeat from 2) until a single community is left.\n",
    "4) Build dendrogram, extract organization structure\n",
    "\n",
    "Running Time:\n",
    "\n",
    "* Step 1 (calculation similarity matrix): $\\mathcal{O}(N^2)$\n",
    "* Step 2-3 (group similarity): $\\mathcal{O}(N^2)$\n",
    "* Step 4 (dendrogram): $\\mathcal{O}(N log N)$\n",
    "Overall $\\mathcal{O}(N^2)$\n",
    "\n",
    "Example: Topological overlap matrix reordered to show high overlap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7233fe75a6cb33f",
   "metadata": {},
   "source": [
    "\n",
    "* Similar to the comparison of graphs with the random graph model, we can compare hierarchical structure by a hierarchical random graph model.\n",
    "* Specify a dendrogram (binary tree) and a set of probabilities at each intersection of the tree.\n",
    "\n",
    "* The probability for an edge between a pair of nodes is equal to the $p$ stored at the lowest common ancestor.\n",
    "* Parameters are the probabilities and the tree structure\n",
    "\n",
    "Assumption in hierarchical clustering: Small modules are nested in larger ones. This is captured by the dendrogram.\n",
    "But does this faithfully reflect an organisational structure in the network or just and artifact of the approach?\n",
    "There are obviously networks with such a structure.\n",
    "\n",
    "#### Hierarchical Netwok Model\n",
    "1) Start with a fully connected module, e.g. five nodes $K_5$\n",
    "2) Create four copies and connect \"peripheral\" nodes to \"central\" nodes of original, e.g. 25 nodes\n",
    "3) Repeat from 2): 4 copies and connected peripheral to original central nodes. (125 nodes, ...)\n",
    "\n",
    "**Scale-free property**\n",
    "The obtained network is scale-free, its degree distribution following a power-law with $k^\\gamma$.\n",
    "$$\\gamma = 1 + \\frac{\\ln 5}{\\ln 4} \\simeq 2.16$$\n",
    "\n",
    "Example:\n",
    "\n",
    "* Largest hub: Starts with degree 4\n",
    "* 2nd step: add 4x4\n",
    "* 3rd step: add 4x4x4\n",
    "* I.e. $4^n$ per iteration\n",
    "\n",
    "After iteration n: $k_n(H_i) = \\sum_{l=1}^i 4^l$ for hub on level $i$\n",
    "\n",
    "(there are four copies of the central nodes with degree from last iteration and so on)\n",
    "\n",
    "__Small $k$ nodes:__\n",
    "\n",
    "* high clustering coefficient\n",
    "* their neighbours tend to link to each other in highly interlinked and compact communities.\n",
    "\n",
    "__High $k$ nodes (hubs):__\n",
    "\n",
    "* small clustering coefficient\n",
    "* Connect independent communities.\n",
    "\n",
    "Green circles: Random rewiring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fdc88f0976f695",
   "metadata": {},
   "source": [
    "\n",
    "#### What is Louvrain\n",
    "Louvrain Community Detection algorithm\n",
    "\n",
    "#### What is Leiden\n",
    "Leiden Community Detection algorithm\n",
    "\n",
    "extracting the community structure of a network based on modularity optimization.\n",
    "\n",
    "Guarantees that communities are well connected\n",
    "it is faster\n",
    "it uncovers better partitions\n",
    "\n",
    "* What is a cluster? How is it defined?\n",
    "I think clustering is a whole nother problem again. I could read up on it if there is a similarity or connection between a cluster and a community.\n",
    "\n",
    "\n",
    "\n",
    "* What is a motif? How is it defined?\n",
    "I think motif is not part of this lecture maybe the next one, at least i didn't see the word anywhere unitl now.\n",
    "\n",
    "* I need to get a handle of the formulas, not only to memorize them but to get a pattern recognition working for me, so i can find things again and again. Currently i am only pattern matching. Probably also because the slides dont seem to follow an understandable order. I should rather read the books but i also want to get what he tells us on the slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9539c1ea02fc989b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2370dcbf5ed234e8",
   "metadata": {},
   "outputs": [],
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
